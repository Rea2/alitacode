{
  "name": "alitacode",
  "displayName": "Alita Code",
  "description": "Your Virtual Coding Assistant, to help you write better code faster",
  "version": "0.3.6",
  "icon": "images/128x128.png",
  "publisher": "ProjectAlita",
  "engines": {
    "vscode": "^1.78.0"
  },
  "categories": [
    "Other",
    "Machine Learning"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "repository": "https://github.com/ProjectAlita/alitacode.git",
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "alitacode.predict",
        "title": "Alita: Predict"
      },
      {
        "command": "alitacode.createPrompt",
        "title": "Alita: Create Prompt"
      },
      {
        "command": "alitacode.addContext",
        "title": "Alita: Extend Context"
      },
      {
        "command": "alitacode.syncPrompts",
        "title": "Alita: Sync External Prompts"
      },
      {
        "command": "alitacode.initAlita",
        "title": "Alita: Init"
      },
      {
        "command": "alitacode.getAvailableAIModels",
        "title": "Alita: Get avaialble AI models from the server"
      },
      {
        "command": "alitacode.displayCurrentAIModel",
        "title": "Alita: Display AI model from properties"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "when": "editorFocus && !editorReadonly",
          "submenu": "alitacode.submenu",
          "group": "Alita"
        }
      ],
      "alitacode.submenu": [
        {
          "when": "editorHasSelection && editorFocus && !editorReadonly && alita.init",
          "command": "alitacode.predict"
        },
        {
          "when": "editorFocus && !editorReadonly && alita.init && alitacode.LocalPrompts",
          "command": "alitacode.createPrompt"
        },
        {
          "when": "editorFocus && !alita.init && alitacode.LLMProvider != 'None'",
          "command": "alitacode.initAlita"
        },
        {
          "when": "editorHasSelection && editorFocus && !editorReadonly && alita.init && alitacode.LocalPrompts",
          "command": "alitacode.addContext"
        },
        {
          "when": "alita.init && alitacode.LLMProvider in alitacode.ExtentablePlatforms",
          "command": "alitacode.syncPrompts"
        }
      ]
    },
    "submenus": [
      {
        "id": "alitacode.submenu",
        "label": "Alita"
      }
    ],
    "keybindings": [
      {
        "command": "alitacode.predict",
        "key": "ctrl+shift+r"
      }
    ],
    "configuration": [
      {
        "title": "Main Settings",
        "properties": {
          "alitacode.providerServerURL": {
            "order": 1,
            "type": "string",
            "default": "",
            "description": "URL to LLM service provider if applicable"
          },
          "alitacode.authToken": {
            "order": 2,
            "type": "string",
            "default": "",
            "description": "This is API Key or Bearer token for LLM service provider if applicable"
          },
          "alitacode.selectModel": {
            "order": 4,
            "type": "null",
            "markdownDescription": "[Click here to select](command:alitacode.getAvailableAIModels)"
          },
          "alitacode.modelName": {
            "order": 5,
            "type": "string",
            "description": "Model name used for local prompts, this is deployment name, and it can be different from case to case"
          },
          "alitacode.projectId": {
            "order": 3,
            "type": "number",
            "default": 1,
            "description": "Project Id in Alita Backened, ignored for OpenAI"
          },
          "alitacode.integrationUid": {
            "order": 6,
            "type": "string",
            "default": "Integration UUID goes here",
            "description": "AI integration Id from Alita Backened, ignored for OpenAI"
          },
          "alitacode.defaultViewMode": {
            "order": 7,
            "type": "string",
            "default": "append",
            "enum": [
              "append",
              "split",
              "replace",
              "prepend"
            ],
            "description": "Select the default display mode for the predictions"
          },
          "alitacode.verifySsl": {
            "order": 8,
            "label": "Verify SSL",
            "type": "boolean",
            "default": true,
            "description": "Verify LLM service provider certificate"
          },
          "alitacode.enable": {
            "order": 9,
            "type": "boolean",
            "default": true,
            "description": "Enable/disable this extension"
          }
        }
      },
      {
        "title": "Advanced Settings",
        "properties": {
          "alitacode.customModelTokens": {
            "order": 1,
            "type": "number",
            "default": 4096,
            "description": "Custom model max tokens used for local prompts"
          },
          "alitacode.maxTokens": {
            "order": 2,
            "label": "Max Tokens default value",
            "type": "number",
            "default": 1024,
            "minimum": 1,
            "maximum": 8096,
            "description": "Max tokens value for the model"
          },
          "alitacode.temperature": {
            "order": 3,
            "label": "Temperature default value",
            "type": "number",
            "default": 0.8,
            "minimum": 0,
            "maximum": 1,
            "description": "Temperature value for the model"
          },
          "alitacode.topK": {
            "order": 4,
            "label": "Top K default value",
            "type": "number",
            "default": 40,
            "minimum": 1,
            "maximum": 40,
            "description": "Top K value for the model"
          },
          "alitacode.topP": {
            "order": 5,
            "label": "Top P default value",
            "type": "number",
            "default": 0.8,
            "minimum": 0,
            "maximum": 1,
            "description": "Top P value for the model"
          }
        }
      }
    ]
  },
  "scripts": {
    "lint": "prettier --write . && eslint .",
    "pretest": "npm run lint",
    "test": "node ./test/runTest.js",
    "esbuild-base": "esbuild ./extension.js --bundle --outfile=out/extension.js --external:vscode --format=cjs --platform=node",
    "esbuild": "npm run esbuild-base -- --sourcemap",
    "esbuild-watch": "npm run esbuild-base -- --sourcemap --watch",
    "prevsce": "npm run esbuild-base -- --minify",
    "vsce": "vsce package",
    "publish": "vsce publish"
  },
  "dependencies": {
    "@azure/openai": "^1.0.0-beta.12",
    "axios": "^1.6.8",
    "form-data": "^4.0.0",
    "squirrelly": "7.9.2",
    "yaml": "^2.4.1"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/mocha": "^10.0.1",
    "@types/node": "20.2.5",
    "@types/vscode": "^1.78.0",
    "@vscode/test-electron": "^2.3.2",
    "@vscode/vsce": "^2.25.0",
    "esbuild": "^0.18.11",
    "eslint": "^8.41.0",
    "eslint-config-prettier": "^8.8.0",
    "glob": "^8.1.0",
    "mocha": "^10.2.0",
    "prettier": "^2.8.8",
    "typescript": "^5.1.3"
  }
}
